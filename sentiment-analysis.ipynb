{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69bc88d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all we need to import, including model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e36be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from dataset\n",
    "train_full = pd.read_pickle(r'./tweets-data/train.pkl')\n",
    "train_embed = pd.read_pickle(r'./sentence-transformers/train_emb.pkl')\n",
    "train_tfidf = pd.read_pickle(r'./tfidf/train_tfidf.pkl')\n",
    "\n",
    "\n",
    "dev_full = pd.read_pickle(r'./tweets-data/dev.pkl')\n",
    "dev_embed = pd.read_pickle(r'./sentence-transformers/dev_emb.pkl')\n",
    "dev_tfidf = pd.read_pickle(r'./tfidf/dev_tfidf.pkl')\n",
    "\n",
    "                               \n",
    "\n",
    "test_full = pd.read_pickle(r'./tweets-data/test.pkl')\n",
    "test_embed = pd.read_pickle(r'./sentence-transformers/test_emb.pkl')\n",
    "test_tfidf = pd.read_pickle(r'./tfidf/test_tfidf.pkl')\n",
    "                             \n",
    "unlabel_full  = pd.read_pickle(r'./tweets-data/unlabeled.pkl')\n",
    "unlabel_embed = pd.read_pickle(r'./sentence-transformers/unlabeled_emb.pkl')\n",
    "unlabel_tfidf = pd.read_pickle(r'./tfidf/unlabeled_tfidf.pkl')\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c8f57fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the label of the data\n",
    "train_label = train_embed['Sentiment']\n",
    "dev_label = dev_embed['Sentiment']\n",
    "test_lable = test_embed['Sentiment']\n",
    "\n",
    "train_group = train_embed['Demographic']\n",
    "dev_group = dev_embed['Demographic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba8bae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the tfidf from the embedded data\n",
    "train_embed_tfidf = pd.DataFrame(train_embed.TFIDF.to_list())\n",
    "dev_embed_tfidf = pd.DataFrame(dev_embed.TFIDF.to_list())\n",
    "test_embed_tfidf = pd.DataFrame(test_embed.TFIDF.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b126d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the text from full data\n",
    "train_full_tfidf = pd.DataFrame(train_full.text.to_list())\n",
    "dev_full_tfidf = pd.DataFrame(dev_full.text.to_list())\n",
    "test_full_tfidf = pd.DataFrame(test_full.text.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb684ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  1 : 0.621\n",
      "i =  2 : 0.6065\n",
      "i =  3 : 0.64225\n",
      "i =  4 : 0.64\n",
      "i =  5 : 0.66275\n",
      "i =  6 : 0.657\n",
      "i =  7 : 0.67625\n",
      "i =  8 : 0.6665\n",
      "i =  9 : 0.676\n",
      "i =  10 : 0.668\n",
      "i =  11 : 0.68075\n",
      "i =  12 : 0.6755\n",
      "i =  13 : 0.67825\n",
      "i =  14 : 0.67725\n",
      "i =  15 : 0.67775\n",
      "i =  16 : 0.68025\n",
      "i =  17 : 0.68575\n",
      "i =  18 : 0.6805\n",
      "i =  19 : 0.685\n",
      "i =  20 : 0.68025\n",
      "i =  21 : 0.68425\n",
      "i =  22 : 0.68675\n",
      "i =  23 : 0.68475\n",
      "i =  24 : 0.68575\n",
      "i =  25 : 0.68325\n",
      "i =  26 : 0.68425\n",
      "i =  27 : 0.68325\n",
      "i =  28 : 0.68375\n",
      "i =  29 : 0.686\n",
      "i =  30 : 0.6855\n",
      "i =  31 : 0.69025\n",
      "i =  32 : 0.691\n",
      "i =  33 : 0.69075\n",
      "i =  34 : 0.68725\n",
      "i =  35 : 0.69075\n",
      "i =  36 : 0.68725\n",
      "i =  37 : 0.68875\n",
      "i =  38 : 0.68975\n",
      "i =  39 : 0.6905\n",
      "i =  40 : 0.68725\n",
      "i =  41 : 0.68725\n",
      "i =  42 : 0.68825\n",
      "i =  43 : 0.6875\n",
      "i =  44 : 0.6875\n",
      "i =  45 : 0.688\n",
      "i =  46 : 0.6915\n",
      "i =  47 : 0.68875\n",
      "i =  48 : 0.68825\n",
      "i =  49 : 0.68575\n",
      "i =  50 : 0.685\n",
      "i =  51 : 0.689\n",
      "i =  52 : 0.68725\n",
      "i =  53 : 0.69\n",
      "i =  54 : 0.68625\n",
      "i =  55 : 0.6885\n",
      "i =  56 : 0.686\n",
      "i =  57 : 0.6875\n",
      "i =  58 : 0.6865\n",
      "i =  59 : 0.68725\n",
      "i =  60 : 0.68775\n",
      "i =  61 : 0.6885\n",
      "i =  62 : 0.68725\n",
      "i =  63 : 0.68875\n",
      "i =  64 : 0.68775\n",
      "i =  65 : 0.68475\n",
      "i =  66 : 0.687\n",
      "i =  67 : 0.68425\n",
      "i =  68 : 0.6865\n",
      "i =  69 : 0.6845\n",
      "i =  70 : 0.685\n",
      "i =  71 : 0.6835\n",
      "i =  72 : 0.68775\n",
      "i =  73 : 0.68525\n",
      "i =  74 : 0.685\n",
      "i =  75 : 0.68525\n",
      "i =  76 : 0.68525\n",
      "i =  77 : 0.68475\n",
      "i =  78 : 0.68575\n",
      "i =  79 : 0.68425\n",
      "i =  80 : 0.6865\n",
      "i =  81 : 0.6815\n",
      "i =  82 : 0.68575\n",
      "i =  83 : 0.68075\n",
      "i =  84 : 0.6845\n",
      "i =  85 : 0.6825\n",
      "i =  86 : 0.68475\n",
      "i =  87 : 0.6835\n",
      "i =  88 : 0.68525\n",
      "i =  89 : 0.68325\n",
      "i =  90 : 0.68425\n",
      "i =  91 : 0.6835\n",
      "i =  92 : 0.685\n",
      "i =  93 : 0.68175\n",
      "i =  94 : 0.6835\n",
      "i =  95 : 0.68275\n",
      "i =  96 : 0.68225\n",
      "i =  97 : 0.68225\n",
      "i =  98 : 0.682\n",
      "i =  99 : 0.68125\n"
     ]
    }
   ],
   "source": [
    "# Choose best K in KNN --> finally, choose K=46\n",
    "K = [0]\n",
    "Acc = [0]\n",
    "for i in range (1,100):\n",
    "    knn = KNeighborsClassifier(i)\n",
    "    knn.fit(train_embed_tfidf, train_label)\n",
    "    knn_pred = knn.predict(dev_embed_tfidf)\n",
    "    print(\"i = \", i, \":\", accuracy_score(dev_label, knn_pred))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7a7bed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-R baseline accuracy: 0.59925\n",
      "GaussianNB accuracy 0.61475\n",
      "KNeighborsClassifier 0.6915\n",
      "LogisticRegression accuracy 0.69825\n"
     ]
    }
   ],
   "source": [
    "# baseline and GaussianNB, KNN, LogisticRegression model\n",
    "baseline = DecisionTreeClassifier(max_depth=1)\n",
    "baseline.fit(train_embed_tfidf,train_label)\n",
    "base_pred = baseline.predict(dev_embed_tfidf)\n",
    "print(\"1-R baseline accuracy:\", accuracy_score(dev_label, base_pred))\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_embed_tfidf, train_label)\n",
    "gnb_pred = gnb.predict(dev_embed_tfidf)\n",
    "print(\"GaussianNB accuracy\", accuracy_score(dev_label, gnb_pred))\n",
    "\n",
    "num_neigh = 46\n",
    "knn = KNeighborsClassifier(num_neigh)\n",
    "knn.fit(train_embed_tfidf, train_label)\n",
    "knn_pred = knn.predict(dev_embed_tfidf)\n",
    "print(\"KNeighborsClassifier\", accuracy_score(dev_label, knn_pred))\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter = 800)\n",
    "lr.fit(train_embed_tfidf, train_label)\n",
    "lr_pred = lr.predict(dev_embed_tfidf)\n",
    "print(\"LogisticRegression accuracy\", accuracy_score(dev_label, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fcab7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add two new feature to the embeded data\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "train_embed_tfidf[384] = train_full.text.apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "train_embed_tfidf[385] = train_full.text.apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "dev_embed_tfidf[384] = dev_full.text.apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "dev_embed_tfidf[385] = dev_full.text.apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "test_embed_tfidf[384] = test_full.text.apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "test_embed_tfidf[385] = test_full.text.apply(lambda x: TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b8dc57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-R baseline accuracy: 0.59925\n",
      "GaussianNB accuracy 0.6165\n",
      "K-NearestNeighborClassifier 0.68875\n",
      "LogisticRegression accuracy 0.6995\n"
     ]
    }
   ],
   "source": [
    "# accuracy of baseline and three models after adding two new feature\n",
    "baseline = DecisionTreeClassifier(max_depth=1)\n",
    "baseline.fit(train_embed_tfidf,train_label)\n",
    "base_pred = baseline.predict(dev_embed_tfidf)\n",
    "print(\"1-R baseline accuracy:\", accuracy_score(dev_label, base_pred))\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_embed_tfidf, train_label)\n",
    "gnb_pred = gnb.predict(dev_embed_tfidf)\n",
    "print(\"GaussianNB accuracy\", accuracy_score(dev_label, gnb_pred))\n",
    "\n",
    "num_neigh = 46\n",
    "knn = KNeighborsClassifier(num_neigh)\n",
    "knn.fit(train_embed_tfidf, train_label)\n",
    "knn_pred = knn.predict(dev_embed_tfidf)\n",
    "print(\"K-NearestNeighborClassifier\", accuracy_score(dev_label, knn_pred))\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter = 800)\n",
    "lr.fit(train_embed_tfidf, train_label)\n",
    "lr_pred = lr.predict(dev_embed_tfidf)\n",
    "print(\"LogisticRegression accuracy\", accuracy_score(dev_label, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "606a1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for select N best feature\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_embed_pos = scaler.fit_transform(train_embed_tfidf)\n",
    "dev_embed_pos = scaler.transform(dev_embed_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "164643ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 chi2 KNN accuracy 0.68475\n",
      "100 mutual KNN accuracy 0.6925\n",
      "200 chi2 KNN accuracy 0.68525\n",
      "200 mutual KNN accuracy 0.68875\n",
      "300 chi2 KNN accuracy 0.686\n",
      "300 mutual KNN accuracy 0.69375\n",
      "all chi2 KNN accuracy 0.687\n",
      "all mutual KNN accuracy 0.687\n"
     ]
    }
   ],
   "source": [
    "#select N best feature (chi2 and mutual_info_classif) -- this is the example of the result by using KNN model\n",
    "ks = [100, 200, 300, \"all\"]\n",
    "num_neigh = 46\n",
    "\n",
    "for k in ks:\n",
    "    x2 = SelectKBest(chi2, k=k)\n",
    "    train_new_chi2 = x2.fit_transform(train_embed_pos, train_label)\n",
    "    test_new_chi2 = x2.transform(dev_embed_pos)\n",
    "    xm = SelectKBest(mutual_info_classif, k=k)\n",
    "    train_new_mutual = xm.fit_transform(train_embed_pos, train_label)\n",
    "    test_new_mutual = xm.transform(dev_embed_pos)\n",
    "    knn = KNeighborsClassifier(num_neigh)\n",
    "    knn.fit(train_new_chi2, train_label)\n",
    "    knn_pred = knn.predict(test_new_chi2)\n",
    "    knn1 = KNeighborsClassifier(num_neigh)\n",
    "    knn1.fit(train_new_mutual, train_label)\n",
    "    knn_pred1 = knn1.predict(test_new_mutual)\n",
    "    print(k, \"chi2\", \"KNN accuracy\", accuracy_score(dev_label, knn_pred))\n",
    "    print(k, \"mutual\", \"KNN accuracy\", accuracy_score(dev_label, knn_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef1521ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 chi2 GaussianNB accuracy 0.61875\n",
      "100 mutual GaussianNB accuracy 0.62725\n",
      "200 chi2 GaussianNB accuracy 0.62\n",
      "200 mutual GaussianNB accuracy 0.62325\n",
      "300 chi2 GaussianNB accuracy 0.6185\n",
      "300 mutual GaussianNB accuracy 0.6155\n",
      "all chi2 GaussianNB accuracy 0.6165\n",
      "all mutual GaussianNB accuracy 0.6165\n"
     ]
    }
   ],
   "source": [
    "#select N best feature (chi2 and mutual_info_classif) -- this is the example of the result by using GaussianNB model\n",
    "ks = [100, 200, 300, \"all\"]\n",
    "for k in ks:\n",
    "    x2 = SelectKBest(chi2, k=k)\n",
    "    train_new_chi2 = x2.fit_transform(train_embed_pos, train_label)\n",
    "    test_new_chi2 = x2.transform(dev_embed_pos)\n",
    "    xm = SelectKBest(mutual_info_classif, k=k)\n",
    "    train_new_mutual = xm.fit_transform(train_embed_pos, train_label)\n",
    "    test_new_mutual = xm.transform(dev_embed_pos)\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(train_new_chi2, train_label)\n",
    "    gnb_pred = gnb.predict(test_new_chi2)\n",
    "    gnb1 = GaussianNB()\n",
    "    gnb1.fit(train_new_mutual, train_label)\n",
    "    gnb_pred1 = gnb1.predict(test_new_mutual)\n",
    "    print(k, \"chi2\", \"GaussianNB accuracy\", accuracy_score(dev_label, gnb_pred))\n",
    "    print(k, \"mutual\", \"GaussianNB accuracy\", accuracy_score(dev_label, gnb_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d958626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 chi2 LogisticRegression accuracy 0.683\n",
      "100 mutual LogisticRegression accuracy 0.6845\n",
      "200 chi2 LogisticRegression accuracy 0.691\n",
      "200 mutual LogisticRegression accuracy 0.68675\n",
      "300 chi2 LogisticRegression accuracy 0.6965\n",
      "300 mutual LogisticRegression accuracy 0.69575\n",
      "all chi2 LogisticRegression accuracy 0.6975\n",
      "all mutual LogisticRegression accuracy 0.6975\n"
     ]
    }
   ],
   "source": [
    "#select N best feature (chi2 and mutual_info_classif) -- this is the example of the result by using LR model\n",
    "ks = [100, 200, 300, \"all\"]\n",
    "for k in ks:\n",
    "    x2 = SelectKBest(chi2, k=k)\n",
    "    train_new_chi2 = x2.fit_transform(train_embed_pos, train_label)\n",
    "    test_new_chi2 = x2.transform(dev_embed_pos)\n",
    "    xm = SelectKBest(mutual_info_classif, k=k)\n",
    "    train_new_mutual = xm.fit_transform(train_embed_pos, train_label)\n",
    "    test_new_mutual = xm.transform(dev_embed_pos)\n",
    "    lr = LogisticRegression(solver='lbfgs', max_iter = 800)\n",
    "    lr.fit(train_new_chi2, train_label)\n",
    "    lr_pred = lr.predict(test_new_chi2)\n",
    "    lr1 = LogisticRegression(solver='lbfgs', max_iter = 800)\n",
    "    lr1.fit(train_new_mutual, train_label)\n",
    "    lr_pred1 = lr1.predict(test_new_mutual)\n",
    "    print(k, \"chi2\", \"LogisticRegression accuracy\", accuracy_score(dev_label, lr_pred))\n",
    "    print(k, \"mutual\", \"LogisticRegression accuracy\", accuracy_score(dev_label, lr_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "186c7524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data from text\n",
    "def clean(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+',\"\",text)\n",
    "    text = re.sub(r'#','',text) \n",
    "    text = re.sub(r'_TWITTER-ENTITY_','',text)\n",
    "    text = re.sub(r'RT[\\s]+','',text)\n",
    "    text = re.sub(r'https?:\\/\\/\\S+','',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14b1c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data from full data\n",
    "def clean_text(test):\n",
    "    k = 0\n",
    "    for i in test.text:\n",
    "        test.text[k] = clean(i)\n",
    "        k += 1\n",
    "    return test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b311cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the tfidf from unlabel embedded data\n",
    "unlabel_embed_tfidf = pd.DataFrame(unlabel_embed.TFIDF.to_list())\n",
    "unlabel_full_tfidf = pd.DataFrame(unlabel_full.text.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4a8ea11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy 0.6895\n"
     ]
    }
   ],
   "source": [
    "#get best knn accuracy after select N best feature\n",
    "\n",
    "num_neigh = 46\n",
    "\n",
    "xm = SelectKBest(mutual_info_classif, k=300)\n",
    "train_new_mutual = xm.fit_transform(train_embed_pos, train_label)\n",
    "test_new_mutual = xm.transform(dev_embed_pos)\n",
    "knn = KNeighborsClassifier(num_neigh)\n",
    "knn.fit(train_new_mutual, train_label)\n",
    "knn_pred = knn.predict(test_new_mutual)\n",
    "print(\"KNN accuracy\", accuracy_score(dev_label, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbf47318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB accuracy 0.628\n"
     ]
    }
   ],
   "source": [
    "#get best GaussianNB accuracy after select N best feature\n",
    "\n",
    "num_neigh = 46\n",
    "\n",
    "xm = SelectKBest(mutual_info_classif, k=100)\n",
    "train_new_mutual = xm.fit_transform(train_embed_pos, train_label)\n",
    "test_new_mutual = xm.transform(dev_embed_pos)\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_new_mutual, train_label)\n",
    "gnb_pred = gnb.predict(test_new_mutual)\n",
    "print(\"GNB accuracy\", accuracy_score(dev_label, gnb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f61d02c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB semi supervised accuracy 0.588\n"
     ]
    }
   ],
   "source": [
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "base = GaussianNB()\n",
    "\n",
    "self_training_model = SelfTrainingClassifier(base, threshold=0.8)\n",
    "semi = pd.concat([train_embed_tfidf, unlabel_embed_tfidf]).reset_index(drop = True)\n",
    "unlabel_lable = pd.Series([-1]*100000)\n",
    "semi_label = pd.concat([train_label, unlabel_lable]).reset_index(drop = True)\n",
    "self_training_model.fit(semi, semi_label)\n",
    "gnb_pred = self_training_model.predict(dev_embed_tfidf)\n",
    "print(\"GaussianNB semi supervised accuracy\", accuracy_score(dev_label, gnb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "561415f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN semi supervised accuracy 0.664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "num_neigh = 46\n",
    "base = KNeighborsClassifier(num_neigh)\n",
    "\n",
    "self_training_model = SelfTrainingClassifier(base, threshold=0.8)\n",
    "semi = pd.concat([train_embed_tfidf, unlabel_embed_tfidf]).reset_index(drop = True)\n",
    "unlabel_lable = pd.Series([-1]*100000)\n",
    "semi_label = pd.concat([train_label, unlabel_lable]).reset_index(drop = True)\n",
    "self_training_model.fit(semi, semi_label)\n",
    "knn_pred = self_training_model.predict(dev_embed_tfidf)\n",
    "print(\"KNN semi supervised accuracy\", accuracy_score(dev_label, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad788430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression semi supervised accuracy 0.70075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "num_neigh = 46\n",
    "base = LogisticRegression(solver='lbfgs', max_iter = 800)\n",
    "\n",
    "self_training_model = SelfTrainingClassifier(base, threshold=0.8)\n",
    "semi = pd.concat([train_embed_tfidf, unlabel_embed_tfidf]).reset_index(drop = True)\n",
    "unlabel_lable = pd.Series([-1]*100000)\n",
    "semi_label = pd.concat([train_label, unlabel_lable]).reset_index(drop = True)\n",
    "self_training_model.fit(semi, semi_label)\n",
    "lr_pred = self_training_model.predict(dev_embed_tfidf)\n",
    "print(\"Logistic Regression semi supervised accuracy\", accuracy_score(dev_label, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1876d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7065"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the mix of different method\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "m1 = gnb\n",
    "m2 = knn\n",
    "m3 = LogisticRegression(solver='lbfgs', max_iter = 1000)\n",
    "estimators = [(\"m1\", m1), (\"m2\", m2), (\"m3\", m3)]\n",
    "final = LogisticRegression(solver = \"lbfgs\", random_state = 1)\n",
    "clf = StackingClassifier(estimators = estimators, final_estimator = final)\n",
    "clf.fit(train_embed_tfidf, train_label).score(dev_embed_tfidf, dev_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "713969e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predicted test label\n",
    "kaggle = clf.predict(test_embed_tfidf)\n",
    "kaggle = pd.DataFrame(kaggle,columns=[\"Category\"])\n",
    "kaggle.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
